# CS50 TSE Querier
## Design Specification
Based on Indexer Design Spec. 

According to the [Querier Requirements Spec](REQUIREMENTS.md), the TSE *querier* "is a standalone program that reads the index file produced by the TSE Indexer, and page files produced by the TSE Querier, and answers search queries submitted via stdin." 

### User interface

The querier requires two command-line arguments and reads queries from stdin.  

```
querier pageDirectory indexFilename
```

For example, if `letters` is a pageDirectory in `letters.index` is an index (both) in `../data`,

``` bash
$ querier ../data/letters ../data/letters.index
```

### Inputs and outputs

**Input**: the querier loads the index from `indexFilename`. 

The querier reads queries from stdin until EOF. For each query, the querier searches the index for documents that match, then uses the page files from `pageDirectory` to extract the documents' urls. 

**Output**: We print the results of each query (to stdout). For example,

```bash
$ ./querier $loc/tse/tse-output/toscrape-depth-1 $loc/tse/tse-output/toscrape-index-1
Query? Europe and travel
Query: europe and travel 
Matches 1 documents (ranked):
score   1 doc  72: http://cs50tse.cs.dartmouth.edu/tse/toscrape/catalogue/category/books/travel_2/index.html
```

### Functional decomposition into modules

We anticipate the following modules or functions:

 1. *main*, which parses arguments, intializes other modules, reads from stdin, and manages overall control flow;
 2. *loadQuery*, which tokenizes the query and ensures that it only contains letters and spaces;
 3. *parseQuery*, which finds documents in the pageDirectory that match the query;
 4. *printResults*, which prints matching documents in decreasing order by score.

And some helper modules that provide data structures:

 1. *index*, a module providing the data structure to represent the in-memory index, and functions to read and write index files;
 2. *webpage*, a module providing the data structure to represent webpages, and to scan a webpage for words;
 3. *pagedir*, a module providing functions to load webpages from files in the pageDirectory;

### Pseudo code for logic/algorithmic flow

The querier will run as follows:

    parse the command line, validate pageDirectory, and load the index
    read line from stdin
    tokenize line with loadQuery, which returns a query_t query
    print the (clean) query
    validate the basic structure of the query
    parse the query (build a counters of results matching the query)
    print the results

### Major data structures

The key data structure is the *query*, holding an input string, an array of pointers to words in the input string, and the number of words in the input string.
The *index* is a *hashtable* keyed by *word* and storing *counters* as items.
The *counters* is keyed by *docID* and stores a count of the number of occurrences of that word in the document with that ID. 
The *twocounters* holds two counters.
The *counter* holds the key and score of a single node/element in a counters.

### Testing plan

*Integration testing*.  The *querier* will be tested with hand-crafted inputs and edge cases, as well as random inputs generated by a fuzz-testing program `fuzzquery.c`.

1. Test `querier` with various invalid and valid arguments.
2. Fuzz-test `querier` with random (valid) arguments.
3. Run *valgrind* on `querier` to ensure no memory leaks or errors.
